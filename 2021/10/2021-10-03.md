### Date
- 

### Note
- 值得注意的是，如何看待神经网络的统计与个例。从哲学角度出发，神经网络适用于从大量样本中提取通用性规律，是否适用于形成精细的逻辑？其对非线性函数的拟合能力有限，且需要大量的数据。
- q learn 对于reward的定义。以及关于训练的策略，通过编写人为的reward函数指导网络，但精细化的reward仍然要使用反复的正负反馈去细化。
- 考虑到以上问题，对于空当接龙游戏，我们可以采用退化的策略，解决该问题的方式暂时不是训练精确的网络，而是训练高效的启发函数，以提高启发式搜索效率作为训练的目的。目标结果暂时不是 “一个给出正确步骤的网络”， “评估各步骤与重点近似距离的网络”
- 修改了技术路线，空当接龙的项目暂时性搁置一下。学习一下pytorch。写一个深度优先搜索算法。